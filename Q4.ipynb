{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFggyiohdpId",
        "outputId": "9a1faa65-14e9-48f9-b8b4-966d9a8c95cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.14.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.17.0)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (63.4.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYObtgTbdtxv"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crJ-c7pFbx1k"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTIL0YlGb-O5"
      },
      "outputs": [],
      "source": [
        "(x_train,y_train),(x_test,y_test)=fashion_mnist.load_data()\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBz8tcRTcAyH"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Neural_network:\n",
        "    def __init__(self,x_train,y_train,input_dim,hidden_layers_size,hidden_layers,output_dim,batch_size=32,epochs=1,activation_func=\"sigmoid\"\n",
        "           ,learning_rate=6e-3 ,decay_rate=0.9,beta=0.9,beta1=0.9,beta2=0.99,optimizer=\"nesterov\",weight_init=\"random\"):\n",
        "\n",
        "        self.x_train,self.x_cv,self.y_train,self.y_cv = train_test_split(x_train, y_train, test_size=0.10, random_state=100,stratify=y_train)\n",
        "\n",
        "        np.random.seed(10)\n",
        "        self.gradient={}\n",
        "        for i in range(hidden_layers+2):\n",
        "            self.gradient[\"W\"+str(i)]=i;\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.hidden_layers_size = hidden_layers_size\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.batch = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.activation_func = activation_func\n",
        "        self.learning_rate = learning_rate\n",
        "        self.decay_rate = decay_rate\n",
        "        self.optimizer = optimizer\n",
        "        for i in range(hidden_layers+2):\n",
        "            self.gradient[\"b\"+str(i)]=i;\n",
        "        self.weight_init = weight_init\n",
        "        self.beta = beta\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.layers = [self.input_dim] + self.hidden_layers*[self.hidden_layers_size] + [self.output_dim]\n",
        "        layers = self.layers.copy()\n",
        "        self.activations = []\n",
        "        self.activation_gradients = []\n",
        "        self.optimizer_list={'gradient_descent':self.gradient_descent,'sgd':self.sgd,'nesterov':self.nesterov,'nadam':self.nadam,'adam':self.adam,'momentum':self.momentum,'rmsprop':self.rmsprop}\n",
        "        self.weights_gradients = []\n",
        "        self.biases_gradients = []\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        n=len(layers)\n",
        "        for i in range(n-1):\n",
        "            if self.weight_init == 'random':\n",
        "                a=np.random.normal(0,0.5,(layers[i],layers[i+1]))\n",
        "                self.weights.append(a)\n",
        "                self.biases.append(np.random.normal(0,0.5,(layers[i+1])))\n",
        "            else :\n",
        "                std = np.sqrt(2/(layers[i]*layers[i+1]))\n",
        "                a=np.random.normal(0,std,(layers[i],layers[i+1]))\n",
        "                self.weights.append(a)\n",
        "                self.biases.append(np.random.normal(0,std,(layers[i+1])))\n",
        "            v1=np.zeros(layers[i])\n",
        "            self.activations.append(v1)\n",
        "            v2=np.zeros(layers[i+1])\n",
        "            self.activation_gradients.append(v2)\n",
        "            self.weights_gradients.append(np.zeros((layers[i],layers[i+1])))\n",
        "            self.biases_gradients.append(v2)\n",
        "        self.activations.append(np.zeros(layers[-1]))\n",
        "        self.optimizer_list[optimizer](self.x_train,self.y_train)\n",
        "            \n",
        "\n",
        "    def sigmoid(self,activations):\n",
        "        res = []\n",
        "        for z in activations:\n",
        "            if z<-40:\n",
        "                res.append(0.0)\n",
        "            elif z>40:\n",
        "                res.append(1.0)\n",
        "            else:\n",
        "                res.append(1/(1+np.exp(-z)))\n",
        "        res=np.asarray(res)\n",
        "        return res\n",
        "\n",
        "    def tanh(self,activations):\n",
        "        res = []\n",
        "        for z in activations:\n",
        "            if z<-20:\n",
        "                res.append(-1.0)\n",
        "            elif z>20:\n",
        "                res.append(1.0)\n",
        "            else:\n",
        "                temp=(np.exp(z) - np.exp(-z))/(np.exp(z) + np.exp(-z))\n",
        "                res.append(temp)\n",
        "        res=np.asarray(res)\n",
        "        return res\n",
        "\n",
        "    def relu(self,activations):\n",
        "        res = []\n",
        "        for i in activations:\n",
        "            if i>0:\n",
        "                res.append(i)\n",
        "            else:\n",
        "                res.append(0)\n",
        "        res=np.asarray(res)\n",
        "        return res\n",
        "\n",
        "    def softmax(self,activations):\n",
        "        tot = 0\n",
        "        res=[]\n",
        "        for z in activations:\n",
        "            tot += np.exp(z)\n",
        "        res=np.asarray([np.exp(z)/tot for z in activations])\n",
        "        return res\n",
        "\n",
        "    def forward_propagation(self,x,y,weights,biases):\n",
        "        n = len(self.layers)\n",
        "        pre_activation=[]\n",
        "        for i in range(n-2):\n",
        "            pre_activation.append(i)\n",
        "        self.activations[0] = x\n",
        "        for i in range(n-2):\n",
        "            if self.activation_func == \"sigmoid\":\n",
        "                s=self.sigmoid(np.matmul(weights[i].T,self.activations[i])+biases[i])\n",
        "                self.activations[i+1] =s\n",
        "            elif self.activation_func == \"tanh\":\n",
        "                t=self.tanh(np.matmul(weights[i].T,self.activations[i])+biases[i])\n",
        "                self.activations[i+1] =t\n",
        "            elif self.activation_func == \"relu\":\n",
        "                r=self.relu(np.matmul(weights[i].T,self.activations[i])+biases[i])\n",
        "                self.activations[i+1] = r\n",
        "        temp=self.softmax(np.matmul(weights[n-2].T,self.activations[n-2])+biases[n-2])\n",
        "        self.activations[n-1] = temp      \n",
        "        return -(np.log2(self.activations[-1][y]))\n",
        "\n",
        "\n",
        "    def grad_w(self,i):\n",
        "        gw=np.matmul(self.activations[i].reshape((-1,1)),self.activation_gradients[i].reshape((1,-1)))\n",
        "        return gw\n",
        "\n",
        "\n",
        "    def grad_b(self,i):\n",
        "        gb=self.activation_gradients[i]\n",
        "        return gb\n",
        "\n",
        "\n",
        "    def backward_propagation(self,x,y,weights,biases):\n",
        "        y_onehot = np.zeros(self.output_dim)\n",
        "        y_onehot[y] = 1\n",
        "        self.activation_gradients[-1] =  -1*(y_onehot - self.activations[-1])\n",
        "        n = len(self.layers)\n",
        "        for i in range(n-2,-1,-1):\n",
        "            gw=self.grad_w(i)\n",
        "            self.weights_gradients[i] += gw\n",
        "            gb= self.grad_b(i)\n",
        "            self.biases_gradients[i] +=gb\n",
        "            if i!=0:\n",
        "                val1=self.activation_gradients[i]\n",
        "                value = np.matmul(weights[i],val1)\n",
        "                if self.activation_func == \"sigmoid\":\n",
        "                    val= value * self.activations[i] * (1-self.activations[i])\n",
        "                    self.activation_gradients[i-1] = val\n",
        "                elif self.activation_func == \"tanh\":\n",
        "                    val=value * (1-np.square(self.activations[i]))\n",
        "                    self.activation_gradients[i-1] = val\n",
        "                elif self.activation_func == \"relu\":\n",
        "                    res = []\n",
        "                    for k in self.activations[i]:\n",
        "                        ans=1.0 if k>0 else 0.0\n",
        "                        res.append(ans)\n",
        "                    res = np.asarray(res)\n",
        "                    self.activation_gradients[i-1] = value * res\n",
        "\n",
        "    def gradient_descent(self,x_train,y_train):\n",
        "        grads=[]\n",
        "        for i in (self.weights_gradients):\n",
        "            grads.append(i)\n",
        "        for i in range(self.epochs):\n",
        "            print('Epoch---',i+1,end=\" \")\n",
        "            loss = 0\n",
        "            val_loss = 0\n",
        "            wg=[]\n",
        "            for i in (self.weights_gradients):\n",
        "                wg.append(0*i)\n",
        "            self.weights_gradients = wg\n",
        "            bg=[]\n",
        "            for i in (self.biases_gradients):\n",
        "              bg.append(0*i)\n",
        "            self.biases_gradients =bg\n",
        "            index = 1\n",
        "            for x,y in zip(x_train,y_train):\n",
        "                x = x.ravel()\n",
        "                val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "                loss += val\n",
        "                self.backward_propagation(x,y,self.weights,self.biases)\n",
        "                temp=index % self.batch\n",
        "                if temp == 0 or index == x_train.shape[0]:\n",
        "                    n=len(self.weights)\n",
        "                    for j in range(n):\n",
        "                        w_g=self.learning_rate * self.weights_gradients[j]\n",
        "                        self.weights[j] -= w_g\n",
        "                        b_g=self.learning_rate * self.biases_gradients[j]\n",
        "                        self.biases[j] -= b_g\n",
        "                    wg=[]\n",
        "                    for i in (self.weights_gradients):\n",
        "                      wg.append(0*i)\n",
        "                    self.weights_gradients = wg\n",
        "                    bg=[]\n",
        "                    for i in (self.biases_gradients):\n",
        "                      bg.append(0*i)\n",
        "                    self.biases_gradients =bg\n",
        "                index += 1 \n",
        "            for x,y in zip(self.x_cv,self.y_cv):\n",
        "               x=x.ravel()\n",
        "               temp=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "               val_loss+=temp\n",
        "            temp1=self.calculate_accuracy(x_train,y_train)\n",
        "            acc=round(temp1,3)\n",
        "            temp2=self.calculate_accuracy(self.x_cv,self.y_cv)\n",
        "            val_acc=round(temp2,3)\n",
        "            print('  loss = ',loss/x_train.shape[0],'  accuracy = ',acc,'   validation loss= ',val_loss/self.x_cv.shape[0],'  validation accuaracy= ',val_acc)\n",
        "\n",
        "    def sgd(self,x_train,y_train):\n",
        "        grads=[]\n",
        "        for i in (self.weights_gradients):\n",
        "            grads.append(i)\n",
        "        t=self.epochs\n",
        "        for i in range(t):\n",
        "            print('Epoch---',i+1,end=\" \")\n",
        "            loss = 0\n",
        "            val_loss=0\n",
        "            index = 1\n",
        "            for x,y in zip(x_train,y_train):\n",
        "                x = x.ravel()\n",
        "                val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "                loss += val\n",
        "                self.backward_propagation(x,y,self.weights,self.biases)\n",
        "                temp=index % self.batch\n",
        "                if  temp== 0 or index == x_train.shape[0]:\n",
        "                    lst=[0*i for i in (self.weights_gradients)]\n",
        "                    for j in range(len(self.weights)):\n",
        "                        temp=self.learning_rate * self.weights_gradients[j]\n",
        "                        self.weights[j] -= temp\n",
        "                        self.biases[j] -= self.learning_rate * self.biases_gradients[j]\n",
        "                    wg=[]\n",
        "                    for i in (self.weights_gradients):\n",
        "                      wg.append(0*i)\n",
        "                    self.weights_gradients = wg\n",
        "                    bg=[]\n",
        "                    for i in (self.biases_gradients):\n",
        "                      bg.append(0*i)\n",
        "                    self.biases_gradients =bg\n",
        "                index +=1   \n",
        "            for x,y in zip(self.x_cv,self.y_cv):\n",
        "               x=x.ravel()\n",
        "               temp=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "               val_loss+=temp\n",
        "            cal_acc=self.calculate_accuracy(x_train,y_train)\n",
        "            acc=round(cal_acc,3)\n",
        "            cal_acc_cv=self.calculate_accuracy(self.x_cv,self.y_cv)\n",
        "            val_acc=round(cal_acc_cv,3)\n",
        "            wandb.log({'train_loss':loss/x_train.shape[0],'train_accuracy':acc,'val_loss':val_loss/self.x_cv.shape[0],'val_accuracy':val_acc})\n",
        "            print('  loss = ',loss/x_train.shape[0],'  accuracy = ',acc,'   validation loss= '\n",
        "                  ,val_loss/self.x_cv.shape[0],'  validation accuaracy= ',val_acc)\n",
        "            \n",
        "    def momentum(self,x_train,y_train):\n",
        "        prev_gradients_w=[]\n",
        "        temp1=[]\n",
        "        for i in (self.weights_gradients):\n",
        "            temp1.append(0*i)\n",
        "        prev_gradients_w=temp1\n",
        "        prev_gradients_b=[]\n",
        "        temp2=[]\n",
        "        for i in (self.biases_gradients):\n",
        "            temp2.append(0*i)\n",
        "        prev_gradients_b=temp2\n",
        "        n=self.epochs\n",
        "\n",
        "        for i in range(n):\n",
        "            print('Epoch---',i+1,end=\" \")\n",
        "            loss = 0\n",
        "            val_loss=0\n",
        "            wg=[]\n",
        "            for i in (self.weights_gradients):\n",
        "              wg.append(0*i)\n",
        "            self.weights_gradients = wg\n",
        "            bg=[]\n",
        "            for i in (self.biases_gradients):\n",
        "              bg.append(0*i)\n",
        "            self.biases_gradients=bg\n",
        "            index = 1\n",
        "            for x,y in zip(x_train,y_train):\n",
        "                x = x.ravel()\n",
        "                val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "                loss += val\n",
        "                self.backward_propagation(x,y,self.weights,self.biases)\n",
        "                temp=index % self.batch\n",
        "                if  temp== 0 or index == x_train.shape[0]:\n",
        "                    lst=[0*i for i in (self.weights_gradients)]\n",
        "                    for j in range(len(self.weights)):\n",
        "                        v1=self.learning_rate * self.weights_gradients[j]\n",
        "                        v_w =(self.decay_rate * prev_gradients_w[j] +v1)\n",
        "                        v2= self.learning_rate * self.biases_gradients[j]\n",
        "                        v_b = (self.decay_rate * prev_gradients_b[j] + v2)\n",
        "                        self.weights[j] -= v_w\n",
        "                        self.biases[j] -= v_b\n",
        "                        prev_gradients_w[j] = v_w\n",
        "                        prev_gradients_b[j] = v_b\n",
        "                    wg=[]\n",
        "                    for i in (self.weights_gradients):\n",
        "                      wg.append(0*i)\n",
        "                    self.weights_gradients = wg\n",
        "                    bg=[]\n",
        "                    for i in (self.biases_gradients):\n",
        "                      bg.append(0*i)\n",
        "                    self.biases_gradients=bg\n",
        "                index +=1\n",
        "            for x,y in zip(self.x_cv,self.y_cv):\n",
        "               x=x.ravel()\n",
        "               val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "               val_loss+=val\n",
        "\n",
        "            cal_acc=self.calculate_accuracy(x_train,y_train)\n",
        "            acc=round(cal_acc,3)\n",
        "            cal_acc_cv=self.calculate_accuracy(self.x_cv,self.y_cv)\n",
        "            val_acc=round(cal_acc_cv,3)\n",
        "            wandb.log({'train_loss':loss/x_train.shape[0],'train_accuracy':acc,'val_loss':val_loss/self.x_cv.shape[0],'val_accuracy':val_acc})\n",
        "            print('  loss = ',loss/x_train.shape[0],'  accuracy = ',acc,'   validation loss= '\n",
        "                  ,val_loss/self.x_cv.shape[0],'  validation accuaracy= ',val_acc)\n",
        "\n",
        "\n",
        "    def nesterov(self,x_train,y_train):\n",
        "        prev_gradients_w=[]\n",
        "        temp1=[]\n",
        "        for i in (self.weights_gradients):\n",
        "            temp1.append(0*i)\n",
        "        prev_gradients_w=temp1\n",
        "        prev_gradients_b=[]\n",
        "        temp2=[]\n",
        "        for i in (self.biases_gradients):\n",
        "            temp2.append(0*i)\n",
        "        prev_gradients_b=temp2\n",
        "\n",
        "        n=self.epochs\n",
        "        for i in range(n):\n",
        "            print('Epoch---',i+1,end=\" \")\n",
        "            loss = 0\n",
        "            val_loss=0\n",
        "            for j in range(len(self.weights)):\n",
        "              temp=self.weights[j] -  (self.decay_rate * prev_gradients_w[j])\n",
        "              self.weights[j]=temp\n",
        "              self.biases[j] =self.biases[j] -  self.decay_rate * prev_gradients_b[j]\n",
        "            wg=[]\n",
        "            for i in (self.weights_gradients):\n",
        "              wg.append(0*i)\n",
        "            self.weights_gradients = wg\n",
        "            bg=[]\n",
        "            for i in (self.biases_gradients):\n",
        "              bg.append(0*i)\n",
        "            self.biases_gradients=bg\n",
        "            index = 1\n",
        "            for x,y in zip(x_train,y_train):\n",
        "                x = x.ravel()\n",
        "                val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "                loss += val\n",
        "                self.backward_propagation(x,y,self.weights,self.biases)\n",
        "                temp=index % self.batch\n",
        "                if temp == 0 or index == x_train.shape[0]:\n",
        "                    lst=[0*i for i in (self.weights_gradients)]\n",
        "                    for j in range(len(self.weights)):\n",
        "                        temp1=self.decay_rate * prev_gradients_w[j] + self.learning_rate*self.weights_gradients[j]\n",
        "                        prev_gradients_w[j] =temp1\n",
        "                        temp2= self.decay_rate * prev_gradients_b[j] + self.learning_rate*self.biases_gradients[j]               \n",
        "                        prev_gradients_b[j] =  temp2\n",
        "                                        \n",
        "                        self.weights[j] -= prev_gradients_w[j]\n",
        "                        self.biases[j] -= prev_gradients_b[j]\n",
        "                    weights = [self.weights[j] -  self.decay_rate * prev_gradients_w[j] for j in range(len(self.weights))]\n",
        "                    biases = [self.biases[j] -  self.decay_rate * prev_gradients_b[j] for j in range(len(self.biases))]\n",
        "                    wg=[]\n",
        "                    for i in (self.weights_gradients):\n",
        "                       wg.append(0*i)\n",
        "                    self.weights_gradients = wg\n",
        "                    bg=[]\n",
        "                    for i in (self.biases_gradients):\n",
        "                      bg.append(0*i)\n",
        "                    self.biases_gradients=bg\n",
        "                index += 1\n",
        "            for x,y in zip(self.x_cv,self.y_cv):\n",
        "               x=x.ravel()\n",
        "               val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "               val_loss+=val\n",
        "            cal_acc=self.calculate_accuracy(x_train,y_train)\n",
        "            acc=round(cal_acc,3)\n",
        "            cal_acc_cv=self.calculate_accuracy(self.x_cv,self.y_cv)\n",
        "            val_acc=round(cal_acc_cv,3)\n",
        "            wandb.log({'train_loss':loss/x_train.shape[0],'train_accuracy':acc,'val_loss':val_loss/self.x_cv.shape[0],'val_accuracy':val_acc})\n",
        "            print('  loss = ',loss/x_train.shape[0],'  accuracy = ',acc,'   validation loss= '\n",
        "                  ,val_loss/self.x_cv.shape[0],'  validation accuaracy= ',val_acc)\n",
        "            \n",
        "    def rmsprop(self,x_train,y_train):\n",
        "        prev_gradients_w=[]\n",
        "        temp1=[]\n",
        "        for i in (self.weights_gradients):\n",
        "            temp1.append(0*i)\n",
        "        prev_gradients_w=temp1\n",
        "        prev_gradients_b=[]\n",
        "        temp2=[]\n",
        "        for i in (self.biases_gradients):\n",
        "            temp2.append(0*i)\n",
        "        prev_gradients_b=temp2\n",
        "        eps = 1e-2\n",
        "        n=self.epochs\n",
        "        for i in range(n):\n",
        "            print('Epoch---',i+1,end=\" \")\n",
        "            loss = 0\n",
        "            val_loss=0\n",
        "            wg=[]\n",
        "            for i in (self.weights_gradients):\n",
        "              wg.append(0*i)\n",
        "            self.weights_gradients = wg\n",
        "            bg=[]\n",
        "            for i in (self.biases_gradients):\n",
        "              bg.append(0*i)\n",
        "            self.biases_gradients=bg \n",
        "            index = 1\n",
        "            for x,y in zip(x_train,y_train):\n",
        "                x = x.ravel()\n",
        "                val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "                loss += val\n",
        "                self.backward_propagation(x,y,self.weights,self.biases)\n",
        "                condt=index%self.batch\n",
        "                if condt == 0 or index == x_train.shape[0]:\n",
        "                    for j in range(len(self.weights)):\n",
        "                        t1=(1-self.beta) * np.square(self.weights_gradients[j])\n",
        "                        v_w = (self.beta * prev_gradients_w[j] +t1)\n",
        "                        t2=(1-self.beta) * np.square(self.biases_gradients[j])\n",
        "                        v_b = (self.beta * prev_gradients_b[j] +t2)\n",
        "                        denom_w=(self.weights_gradients[j] /(np.sqrt(v_w + eps)))\n",
        "                        self.weights[j] -= self.learning_rate * denom_w\n",
        "                        denom_b=(self.biases_gradients[j] /(np.sqrt(v_b + eps)))\n",
        "                        self.biases[j] -= self.learning_rate * denom_b\n",
        "                        prev_gradients_w[j] = v_w\n",
        "                        prev_gradients_b[j] = v_b\n",
        "                    wg=[]\n",
        "                    for i in (self.weights_gradients):\n",
        "                      wg.append(0*i)\n",
        "                    self.weights_gradients=wg\n",
        "                    bg=[]\n",
        "                    for i in (self.biases_gradients):\n",
        "                      bg.append(0*i)\n",
        "                    self.biases_gradients=bg\n",
        "                index +=1\n",
        "            for x,y in zip(self.x_cv,self.y_cv):\n",
        "               x=x.ravel()\n",
        "               val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "               val_loss+=val\n",
        "\n",
        "            cal_acc=self.calculate_accuracy(x_train,y_train)\n",
        "            acc=round(cal_acc,3)\n",
        "            cal_acc_cv=self.calculate_accuracy(self.x_cv,self.y_cv)\n",
        "            val_acc=round(cal_acc_cv,3)\n",
        "            wandb.log({'train_loss':loss/x_train.shape[0],'train_accuracy':acc,'val_loss':val_loss/self.x_cv.shape[0],'val_accuracy':val_acc})\n",
        "            print('  loss = ',loss/x_train.shape[0],'  accuracy = ',acc,'   validation loss= '\n",
        "                  ,val_loss/self.x_cv.shape[0],'  validation accuaracy= ',val_acc)\n",
        "\n",
        "\n",
        "    def adam(self,x_train,y_train):\n",
        "        m_prev_gradients_w=[]\n",
        "        temp1=[]\n",
        "        for i in (self.weights_gradients):\n",
        "            temp1.append(0*i)\n",
        "        m_prev_gradients_w=temp1\n",
        "        m_prev_gradients_b=[]\n",
        "        temp2=[]\n",
        "        for i in (self.biases_gradients):\n",
        "            temp2.append(0*i)\n",
        "        m_prev_gradients_b=temp2\n",
        "\n",
        "        v_prev_gradients_w=[]\n",
        "        temp3=[]\n",
        "        for i in (self.weights_gradients):\n",
        "            temp3.append(0*i)\n",
        "        v_prev_gradients_w=temp3\n",
        "        v_prev_gradients_b=[]\n",
        "        temp4=[]\n",
        "        for i in (self.biases_gradients):\n",
        "            temp4.append(0*i)\n",
        "        v_prev_gradients_b=temp4\n",
        "        iter = 1\n",
        "        n=self.epochs\n",
        "        for i in range(n):\n",
        "            print('Epoch---',i+1,end=\" \")\n",
        "            loss = 0\n",
        "            val_loss=0\n",
        "            eps = 1e-2\n",
        "            wg=[]\n",
        "            for i in (self.weights_gradients):\n",
        "              wg.append(0*i)\n",
        "            self.weights_gradients = wg\n",
        "            bg=[]\n",
        "            for i in (self.biases_gradients):\n",
        "              bg.append(0*i)\n",
        "            self.biases_gradients=bg \n",
        "            index = 1\n",
        "            for x,y in zip(x_train,y_train):\n",
        "                x = x.ravel()\n",
        "                val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "                loss +=val \n",
        "                self.backward_propagation(x,y,self.weights,self.biases)\n",
        "                condt=index%self.batch\n",
        "                if condt == 0 or index == x_train.shape[0]:\n",
        "                    s=len(self.weights)\n",
        "                    for j in range(s):\n",
        "                        p1=(1-self.beta1) * self.weights_gradients[j]\n",
        "                        m_w = (self.beta1 * m_prev_gradients_w[j]) + p1\n",
        "                        p2=(1-self.beta1) * self.biases_gradients[j]\n",
        "                        m_b = (self.beta1 * m_prev_gradients_b[j]) + p2\n",
        "                        p3=(1-self.beta2) * np.square(self.weights_gradients[j])\n",
        "                        v_w = (self.beta2 * v_prev_gradients_w[j]) + p3\n",
        "                        p4=(1-self.beta2) * np.square(self.biases_gradients[j])\n",
        "                        v_b = (self.beta2 * v_prev_gradients_b[j]) + p4\n",
        "                        denom1=(1-(self.beta1)**iter)\n",
        "                        m_hat_w = (m_w)/ denom1\n",
        "                        m_hat_b = (m_b)/denom1\n",
        "                        denom2=(1-(self.beta2)**iter)\n",
        "                        v_hat_w = (v_w)/ denom2\n",
        "                        v_hat_b = (v_b)/denom2\n",
        "                        t1=(m_hat_w/(np.sqrt(v_hat_w + eps)))\n",
        "                        self.weights[j] -= self.learning_rate * t1\n",
        "                        t2=(m_hat_b/(np.sqrt(v_hat_b + eps)))\n",
        "                        self.biases[j] -= self.learning_rate * t2\n",
        "                        v1=m_prev_gradients_w[j]\n",
        "                        m_prev_gradients_w[j] = m_w\n",
        "                        m_prev_gradients_b[j] = m_b\n",
        "                        v2=v_prev_gradients_w[j]\n",
        "                        v_prev_gradients_w[j] = v_w\n",
        "                        v_prev_gradients_b[j] = v_b\n",
        "                        wg=[]\n",
        "                        for i in (self.weights_gradients):\n",
        "                           wg.append(0*i)\n",
        "                        self.weights_gradients = wg\n",
        "                        bg=[]\n",
        "                        for i in (self.biases_gradients):\n",
        "                          bg.append(0*i)\n",
        "                        self.biases_gradients=bg\n",
        "                    iter += 1\n",
        "                index +=1\n",
        "            for x,y in zip(self.x_cv,self.y_cv):\n",
        "               x=x.ravel()\n",
        "               val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "               val_loss+=val\n",
        "            cal_acc=self.calculate_accuracy(x_train,y_train)\n",
        "            acc=round(cal_acc,3)\n",
        "            cal_acc_cv=self.calculate_accuracy(self.x_cv,self.y_cv)\n",
        "            val_acc=round(cal_acc_cv,3)\n",
        "            wandb.log({'train_loss':loss/x_train.shape[0],'train_accuracy':acc,'val_loss':val_loss/self.x_cv.shape[0],'val_accuracy':val_acc})\n",
        "            print('  loss = ',loss/x_train.shape[0],'  accuracy = ',acc,'   validation loss= '\n",
        "                  ,val_loss/self.x_cv.shape[0],'  validation accuaracy= ',val_acc)\n",
        "        \n",
        "\n",
        "    def nadam(self,x_train,y_train):\n",
        "        m_prev_gradients_w=[]\n",
        "        temp1=[]\n",
        "        for i in (self.weights_gradients):\n",
        "            temp1.append(0*i)\n",
        "        m_prev_gradients_w=temp1\n",
        "        m_prev_gradients_b=[]\n",
        "        temp2=[]\n",
        "        for i in (self.biases_gradients):\n",
        "            temp2.append(0*i)\n",
        "        m_prev_gradients_b=temp2\n",
        "\n",
        "        v_prev_gradients_w=[]\n",
        "        temp3=[]\n",
        "        for i in (self.weights_gradients):\n",
        "            temp3.append(0*i)\n",
        "        v_prev_gradients_w=temp3\n",
        "        v_prev_gradients_b=[]\n",
        "        temp4=[]\n",
        "        for i in (self.biases_gradients):\n",
        "            temp4.append(0*i)\n",
        "        v_prev_gradients_b=temp4\n",
        "        iter = 1\n",
        "        n=self.epochs\n",
        "        for i in range(n):\n",
        "            print('Epoch---',i+1,end=\" \")\n",
        "            loss = 0\n",
        "            val_loss=0\n",
        "            eps = 1e-2\n",
        "            wg=[]\n",
        "            for i in (self.weights_gradients):\n",
        "              wg.append(0*i)\n",
        "            self.weights_gradients = wg\n",
        "            bg=[]\n",
        "            for i in (self.biases_gradients):\n",
        "              bg.append(0*i)\n",
        "            self.biases_gradients=bg \n",
        "            index = 1\n",
        "            for x,y in zip(x_train,y_train):\n",
        "                x = x.ravel()\n",
        "                val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "                loss += val\n",
        "                self.backward_propagation(x,y,self.weights,self.biases)\n",
        "                condt=index % self.batch\n",
        "                if condt == 0 or index == x_train.shape[0]:\n",
        "                    s=len(self.weights)\n",
        "                    for j in range(s):\n",
        "                        p1=(1-self.beta1) * self.weights_gradients[j]\n",
        "                        m_w = (self.beta1 * m_prev_gradients_w[j]) + p1\n",
        "                        p2=(1-self.beta1) * self.biases_gradients[j]\n",
        "                        m_b = (self.beta1 * m_prev_gradients_b[j]) + p2\n",
        "                        p3=(1-self.beta2) * np.square(self.weights_gradients[j])\n",
        "                        v_w = (self.beta2 * v_prev_gradients_w[j]) + p3\n",
        "                        p4=(1-self.beta2) * np.square(self.biases_gradients[j])\n",
        "                        v_b = (self.beta2 * v_prev_gradients_b[j]) + p4\n",
        "                        denom1=(1-(self.beta1)**iter)\n",
        "                        m_hat_w = (m_w)/ denom1\n",
        "                        m_hat_b = (m_b)/denom1\n",
        "                        denom2=(1-(self.beta2)**iter)\n",
        "                        v_hat_w = (v_w)/ denom2\n",
        "                        v_hat_b = (v_b)/denom2\n",
        "                        t3=(1-self.beta1) * self.weights_gradients[j]\n",
        "                        m_dash_w = self.beta1 * m_hat_w + t3\n",
        "                        t4=(1-self.beta1) * self.biases_gradients[j]\n",
        "                        m_dash_b = self.beta1 * m_hat_b + t4\n",
        "                        t1=(m_dash_w/(np.sqrt(v_hat_w + eps)))\n",
        "                        self.weights[j] -= self.learning_rate * t1\n",
        "                        t2=(m_dash_b/(np.sqrt(v_hat_b + eps)))\n",
        "                        self.biases[j] -= self.learning_rate * t2\n",
        "                        v1=m_prev_gradients_w[j]\n",
        "                        m_prev_gradients_w[j] = m_w\n",
        "                        v2=m_prev_gradients_b[j]\n",
        "                        m_prev_gradients_b[j] = m_b\n",
        "                        v_prev_gradients_w[j] = v_w\n",
        "                        v_prev_gradients_b[j] = v_b\n",
        "                        wg=[]\n",
        "                        for i in (self.weights_gradients):\n",
        "                           wg.append(0*i)\n",
        "                        self.weights_gradients = wg\n",
        "                        bg=[]\n",
        "                        for i in (self.biases_gradients):\n",
        "                          bg.append(0*i)\n",
        "                        self.biases_gradients=bg\n",
        "                    iter += 1\n",
        "                index +=1\n",
        "            for x,y in zip(self.x_cv,self.y_cv):\n",
        "               x=x.ravel()\n",
        "               val=self.forward_propagation(x,y,self.weights,self.biases)\n",
        "               val_loss+=val\n",
        "            cal_acc=self.calculate_accuracy(x_train,y_train)\n",
        "            acc=round(cal_acc,3)\n",
        "            cal_acc_cv=self.calculate_accuracy(self.x_cv,self.y_cv)\n",
        "            val_acc=round(cal_acc_cv,3)\n",
        "            wandb.log({'train_loss':loss/x_train.shape[0],'train_accuracy':acc,'val_loss':val_loss/self.x_cv.shape[0],'val_accuracy':val_acc})\n",
        "            print('  loss = ',loss/x_train.shape[0],'  accuracy = ',acc,'   validation loss= '\n",
        "                  ,val_loss/self.x_cv.shape[0],'  validation accuaracy= ',val_acc)\n",
        "    \n",
        "    def calculate_accuracy(self,X,Y):\n",
        "        count = 0\n",
        "        n=len(X)\n",
        "        for i in range(n):\n",
        "            if self.predict(X[i]) == Y[i]:\n",
        "                count+=1\n",
        "        res=count/n\n",
        "        return res\n",
        "\n",
        "    def predict(self,x):\n",
        "        n=len(self.layers)\n",
        "        x = x.ravel()\n",
        "        self.activations[0] = x\n",
        "        for i in range(n-2):\n",
        "            if self.activation_func == \"sigmoid\":\n",
        "                val=self.sigmoid(np.matmul(self.weights[i].T,self.activations[i])+self.biases[i])\n",
        "                self.activations[i+1] = val\n",
        "            elif self.activation_func == \"tanh\":\n",
        "                val=self.tanh(np.matmul(self.weights[i].T,self.activations[i])+self.biases[i])\n",
        "                self.activations[i+1] = val\n",
        "            elif self.activation_func == \"relu\":\n",
        "                val=self.relu(np.matmul(self.weights[i].T,self.activations[i])+self.biases[i])\n",
        "                self.activations[i+1] = val\n",
        "\n",
        "        self.activations[n-1] = self.softmax(np.matmul(self.weights[n-2].T,self.activations[n-2])+self.biases[n-2])\n",
        "\n",
        "        return np.argmax(self.activations[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7J4bOBAcDHp"
      },
      "outputs": [],
      "source": [
        "sweep_config={\n",
        "    'method': 'bayes',\n",
        "    'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters':{\n",
        "        'epochs':{\n",
        "            'values':[3,5,7,10]\n",
        "        },\n",
        "        'weight_decay':{\n",
        "            'values':[0.1,0.0,0.8,0.9]\n",
        "        },\n",
        "        'batch_size':{\n",
        "            'values':[32,64,128]\n",
        "        },\n",
        "        'learning_rate':{\n",
        "            'values':[5e-3,2e-3,6e-3,5e-4]\n",
        "        },\n",
        "        'hidden_layers':{\n",
        "            'values':[1,2,3]\n",
        "        },\n",
        "        'optimizer':{\n",
        "            'values':['sgd','momentum','nesterov','adam','rmsprop','nadam']\n",
        "        },\n",
        "        'hidden_layers_size':{\n",
        "            'values':[16,32,64]\n",
        "        },\n",
        "        'activation':{\n",
        "            'values':['sigmoid','tanh','relu']\n",
        "        },\n",
        "        'weight_init':{\n",
        "            'values':['random','xavier']\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mkoUN2zcC5X"
      },
      "outputs": [],
      "source": [
        "def train(): \n",
        "    res=[]\n",
        "    for i in range(10):\n",
        "      res.append(0);\n",
        "    config_defaults={\n",
        "      'epochs':5,\n",
        "      'batch_size':16,\n",
        "      'learning_rate':1e-3,\n",
        "      'activation':'relu',\n",
        "      'optimizer':'nadam',\n",
        "      'hidden_layers_size':32,\n",
        "      'hidden_layers':3,\n",
        "      'weight_init':'xavier' }\n",
        "    \n",
        "    \n",
        "    \n",
        "    wandb.init(project = 'DL_Assignment1' , config=config_defaults)\n",
        "    config=wandb.config\n",
        "    wandb.run.name = 'op_{}_act_{}_lr_{}_layer_{}_bth_{}'.format(config.optimizer,config.activation,config.learning_rate,config.hidden_layers,config.batch_size)\n",
        "\n",
        "    Neural_network(x_train,y_train,len(x_train[0].ravel()),config.hidden_layers_size,config.hidden_layers,max(y_train)+1,\n",
        "                       config.batch_size,config.epochs,config.activation,\n",
        "                 config.learning_rate,config.weight_decay,0.9,0.9,0.99\n",
        "                        ,config.optimizer,config.weight_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLty5lQ4eJKh",
        "outputId": "8acd80db-018e-44eb-980c-45a95d3dd4a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: smdt8wfp\n",
            "Sweep URL: https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config,project=\"a1_collab\", entity=\"cs22m069\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cc9b6ba131514739a7cd641139aea5a7",
            "660a1fb41f5549cab31b91976e1aad1f",
            "704134a03b014e83a177b1af2cfa3522",
            "9932632c62604d239adaeab2c4390f50",
            "27f924fd78f540589d6a7de10f146aca",
            "ec053bcfbff24ee48aa77cc56a2c3b50",
            "4be4023fdb6347d88a5312ae9bd66ae5",
            "9efcad429c654a7082a779480938fc0e",
            "14f379095e594ae2be43f9afc377cc76",
            "426c81f652af460e83f1693ce9e74f64",
            "0e8375d90d124ac9ae4510306ec4c44b",
            "6e333a0069ec4f4a874d44a9670b5b78",
            "9cee538b86be41bda9a80fb0b31677e8",
            "0a1ef169eeb04751b1e99786d51a1442",
            "7c3ddebb83a84358b082fddad5d7e8cb",
            "6b832571bafa4824b6813b04d4f8fc51",
            "5652d4506f504ea0a484ab840fe2680c",
            "2d05566aaf9a426c91b6d89f455b8331",
            "8b4145f78d444bbda40e5c29b50f009f",
            "f72cb89959284ce9bfe92618d67c95d1",
            "4953d759018d45b6b9dcd646e3349b7a",
            "c3b48a04af7644829c3e5e82b3ce6657",
            "d10eb1c58573437d9b720b9ac5b34898",
            "bc20494fa739429d867ba36e9eea7cbe",
            "db097b761def408a88f5dc6d57c3ba0b"
          ]
        },
        "id": "lKqwMkOCeQZG",
        "outputId": "6872117c-813c-45f1-f8b0-5ada10a34314"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 73qm6qtj with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m069\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230319_110819-73qm6qtj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m069/a1_collab/runs/73qm6qtj' target=\"_blank\">sunny-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m069/a1_collab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m069/a1_collab' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m069/a1_collab/runs/73qm6qtj' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/runs/73qm6qtj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch--- 1   loss =  3.233579227279614   accuracy =  0.378    validation loss=  3.222621707702519   validation accuaracy=  0.374\n",
            "Epoch--- 2   loss =  3.2186653632373714   accuracy =  0.386    validation loss=  3.21722277383914   validation accuaracy=  0.383\n",
            "Epoch--- 3   loss =  3.2148855692845495   accuracy =  0.39    validation loss=  3.214658437509127   validation accuaracy=  0.387\n",
            "Epoch--- 4   loss =  3.212933774020543   accuracy =  0.391    validation loss=  3.213144495488344   validation accuaracy=  0.389\n",
            "Epoch--- 5   loss =  3.211672411813361   accuracy =  0.393    validation loss=  3.21209942008972   validation accuaracy=  0.391\n",
            "Epoch--- 6   loss =  3.2107573257749524   accuracy =  0.395    validation loss=  3.2113164539997996   validation accuaracy=  0.393\n",
            "Epoch--- 7   loss =  3.2100483126569412   accuracy =  0.396    validation loss=  3.2106975670074793   validation accuaracy=  0.394\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc9b6ba131514739a7cd641139aea5a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.523884…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▄▆▆▇██</td></tr><tr><td>train_loss</td><td>█▄▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▆▇██</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.396</td></tr><tr><td>train_loss</td><td>3.21005</td></tr><tr><td>val_accuracy</td><td>0.394</td></tr><tr><td>val_loss</td><td>3.2107</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sunny-sweep-1</strong> at: <a href='https://wandb.ai/cs22m069/a1_collab/runs/73qm6qtj' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/runs/73qm6qtj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230319_110819-73qm6qtj/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: chx7c8hb with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230319_113028-chx7c8hb</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m069/a1_collab/runs/chx7c8hb' target=\"_blank\">breezy-sweep-2</a></strong> to <a href='https://wandb.ai/cs22m069/a1_collab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m069/a1_collab' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m069/a1_collab/runs/chx7c8hb' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/runs/chx7c8hb</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch--- 1   loss =  3.2603192038542974   accuracy =  0.103    validation loss=  3.2531188077657403   validation accuaracy=  0.102\n",
            "Epoch--- 2   loss =  3.250716608459228   accuracy =  0.104    validation loss=  3.2497041237497197   validation accuaracy=  0.104\n",
            "Epoch--- 3   loss =  3.248275895373287   accuracy =  0.109    validation loss=  3.2479299015386913   validation accuaracy=  0.111\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14f379095e594ae2be43f9afc377cc76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▂█</td></tr><tr><td>train_loss</td><td>█▂▁</td></tr><tr><td>val_accuracy</td><td>▁▃█</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.109</td></tr><tr><td>train_loss</td><td>3.24828</td></tr><tr><td>val_accuracy</td><td>0.111</td></tr><tr><td>val_loss</td><td>3.24793</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">breezy-sweep-2</strong> at: <a href='https://wandb.ai/cs22m069/a1_collab/runs/chx7c8hb' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/runs/chx7c8hb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230319_113028-chx7c8hb/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9c94zhxd with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230319_114828-9c94zhxd</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m069/a1_collab/runs/9c94zhxd' target=\"_blank\">neat-sweep-3</a></strong> to <a href='https://wandb.ai/cs22m069/a1_collab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m069/a1_collab' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m069/a1_collab/runs/9c94zhxd' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/runs/9c94zhxd</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch--- 1   loss =  2.579216802399296   accuracy =  0.732    validation loss=  1.2452753791951696   validation accuaracy=  0.722\n",
            "Epoch--- 2   loss =  1.0349468457685094   accuracy =  0.779    validation loss=  0.9842813962749339   validation accuaracy=  0.771\n",
            "Epoch--- 3   loss =  0.8775525235473229   accuracy =  0.803    validation loss=  0.8797170852044014   validation accuaracy=  0.792\n",
            "Epoch--- 4   loss =  0.8005389231793493   accuracy =  0.815    validation loss=  0.8206188140497328   validation accuaracy=  0.802\n",
            "Epoch--- 5   loss =  0.7501892958099687   accuracy =  0.824    validation loss=  0.7816635092368283   validation accuaracy=  0.813\n",
            "Epoch--- 6   loss =  0.7135122369483275   accuracy =  0.831    validation loss=  0.7506809575266029   validation accuaracy=  0.821\n",
            "Epoch--- 7   loss =  0.6848822102096442   accuracy =  0.837    validation loss=  0.7287889783077691   validation accuaracy=  0.825\n",
            "Epoch--- 8   loss =  0.6618466161836251   accuracy =  0.84    validation loss=  0.7118680181894487   validation accuaracy=  0.828\n",
            "Epoch--- 9   loss =  0.6429492572432337   accuracy =  0.844    validation loss=  0.6975208508357964   validation accuaracy=  0.831\n",
            "Epoch--- 10   loss =  0.6266509000345835   accuracy =  0.848    validation loss=  0.6842920034210931   validation accuaracy=  0.835\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5652d4506f504ea0a484ab840fe2680c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.848</td></tr><tr><td>train_loss</td><td>0.62665</td></tr><tr><td>val_accuracy</td><td>0.835</td></tr><tr><td>val_loss</td><td>0.68429</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">neat-sweep-3</strong> at: <a href='https://wandb.ai/cs22m069/a1_collab/runs/9c94zhxd' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/runs/9c94zhxd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230319_114828-9c94zhxd/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 48w0ku0h with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230319_115540-48w0ku0h</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m069/a1_collab/runs/48w0ku0h' target=\"_blank\">rare-sweep-4</a></strong> to <a href='https://wandb.ai/cs22m069/a1_collab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m069/a1_collab' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m069/a1_collab/runs/48w0ku0h' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/runs/48w0ku0h</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch--- 1   loss =  37.198882051837366   accuracy =  0.591    validation loss=  16.67666517588   validation accuaracy=  0.591\n",
            "Epoch--- 2   loss =  13.181829432703783   accuracy =  0.672    validation loss=  11.265379009198567   validation accuaracy=  0.671\n",
            "Epoch--- 3   loss =  9.722038349202181   accuracy =  0.705    validation loss=  9.161490686844195   validation accuaracy=  0.708\n",
            "Epoch--- 4   loss =  8.128663165100058   accuracy =  0.723    validation loss=  8.039594337752954   validation accuaracy=  0.722\n",
            "Epoch--- 5   loss =  7.069094040387443   accuracy =  0.736    validation loss=  7.294501503053387   validation accuaracy=  0.734\n",
            "Epoch--- 6   loss =  6.2889971701063   accuracy =  0.748    validation loss=  6.702065939985256   validation accuaracy=  0.737\n",
            "Epoch--- 7   loss =  5.705162292064604   accuracy =  0.76    validation loss=  6.292271516791289   validation accuaracy=  0.744\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▄▆▆▇██</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇███</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.76</td></tr><tr><td>train_loss</td><td>5.70516</td></tr><tr><td>val_accuracy</td><td>0.744</td></tr><tr><td>val_loss</td><td>6.29227</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rare-sweep-4</strong> at: <a href='https://wandb.ai/cs22m069/a1_collab/runs/48w0ku0h' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/runs/48w0ku0h</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230319_115540-48w0ku0h/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u16jk1us with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230319_120530-u16jk1us</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m069/a1_collab/runs/u16jk1us' target=\"_blank\">lemon-sweep-5</a></strong> to <a href='https://wandb.ai/cs22m069/a1_collab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m069/a1_collab' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/sweeps/smdt8wfp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m069/a1_collab/runs/u16jk1us' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/runs/u16jk1us</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch--- 1   loss =  16.00787044575227   accuracy =  0.628    validation loss=  5.1851300276211   validation accuaracy=  0.623\n",
            "Epoch--- 2   loss =  3.9780494396150217   accuracy =  0.7    validation loss=  3.2838425478140256   validation accuaracy=  0.693\n",
            "Epoch--- 3   loss =  2.803557401720445   accuracy =  0.733    validation loss=  2.5659712101733714   validation accuaracy=  0.725\n",
            "Epoch--- 4   loss =  2.293663614783741   accuracy =  0.754    validation loss=  2.219787454100948   validation accuaracy=  0.746\n",
            "Epoch--- 5   loss =  1.9971209312868314   accuracy =  0.768    validation loss=  1.992894226303337   validation accuaracy=  0.761\n",
            "Epoch--- 6   loss =  1.7905732537034094   accuracy =  0.777    validation loss=  1.8097494442721784   validation accuaracy=  0.772\n",
            "Epoch--- 7   loss =  1.6296774749298886   accuracy =  0.784    validation loss=  1.6721680263023202   validation accuaracy=  0.777\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db097b761def408a88f5dc6d57c3ba0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▄▆▇▇██</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇▇██</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.784</td></tr><tr><td>train_loss</td><td>1.62968</td></tr><tr><td>val_accuracy</td><td>0.777</td></tr><tr><td>val_loss</td><td>1.67217</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lemon-sweep-5</strong> at: <a href='https://wandb.ai/cs22m069/a1_collab/runs/u16jk1us' target=\"_blank\">https://wandb.ai/cs22m069/a1_collab/runs/u16jk1us</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230319_120530-u16jk1us/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.agent(sweep_id,train,count = 5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a1ef169eeb04751b1e99786d51a1442": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e8375d90d124ac9ae4510306ec4c44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3ddebb83a84358b082fddad5d7e8cb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b832571bafa4824b6813b04d4f8fc51",
            "value": 1
          }
        },
        "14f379095e594ae2be43f9afc377cc76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_426c81f652af460e83f1693ce9e74f64",
              "IPY_MODEL_0e8375d90d124ac9ae4510306ec4c44b"
            ],
            "layout": "IPY_MODEL_6e333a0069ec4f4a874d44a9670b5b78"
          }
        },
        "27f924fd78f540589d6a7de10f146aca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d05566aaf9a426c91b6d89f455b8331": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4953d759018d45b6b9dcd646e3349b7a",
            "placeholder": "​",
            "style": "IPY_MODEL_c3b48a04af7644829c3e5e82b3ce6657",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "426c81f652af460e83f1693ce9e74f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cee538b86be41bda9a80fb0b31677e8",
            "placeholder": "​",
            "style": "IPY_MODEL_0a1ef169eeb04751b1e99786d51a1442",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "4953d759018d45b6b9dcd646e3349b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be4023fdb6347d88a5312ae9bd66ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5652d4506f504ea0a484ab840fe2680c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d05566aaf9a426c91b6d89f455b8331",
              "IPY_MODEL_8b4145f78d444bbda40e5c29b50f009f"
            ],
            "layout": "IPY_MODEL_f72cb89959284ce9bfe92618d67c95d1"
          }
        },
        "660a1fb41f5549cab31b91976e1aad1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27f924fd78f540589d6a7de10f146aca",
            "placeholder": "​",
            "style": "IPY_MODEL_ec053bcfbff24ee48aa77cc56a2c3b50",
            "value": "0.001 MB of 0.002 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "6b832571bafa4824b6813b04d4f8fc51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e333a0069ec4f4a874d44a9670b5b78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "704134a03b014e83a177b1af2cfa3522": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4be4023fdb6347d88a5312ae9bd66ae5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9efcad429c654a7082a779480938fc0e",
            "value": 0.5238845144356955
          }
        },
        "7c3ddebb83a84358b082fddad5d7e8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b4145f78d444bbda40e5c29b50f009f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d10eb1c58573437d9b720b9ac5b34898",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc20494fa739429d867ba36e9eea7cbe",
            "value": 1
          }
        },
        "9932632c62604d239adaeab2c4390f50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cee538b86be41bda9a80fb0b31677e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9efcad429c654a7082a779480938fc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc20494fa739429d867ba36e9eea7cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3b48a04af7644829c3e5e82b3ce6657": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc9b6ba131514739a7cd641139aea5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_660a1fb41f5549cab31b91976e1aad1f",
              "IPY_MODEL_704134a03b014e83a177b1af2cfa3522"
            ],
            "layout": "IPY_MODEL_9932632c62604d239adaeab2c4390f50"
          }
        },
        "d10eb1c58573437d9b720b9ac5b34898": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec053bcfbff24ee48aa77cc56a2c3b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f72cb89959284ce9bfe92618d67c95d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "rsZez2PwRsAT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=fashion_mnist.load_data()\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua_9ijmGRuE5",
        "outputId": "931b7d2c-bbf7-4abc-b54f-47a91e58fa74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2chHHNMBN2_L"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Neural_network:\n",
        "    def __init__(self,x_train,y_train,input_dim,hidden_layers_size,hidden_layers,output_dim,batch_size=32,epochs=1,activation_func=\"sigmoid\"\n",
        "           ,learning_rate=6e-3 ,decay_rate=0.9,beta=0.9,beta1=0.9,beta2=0.99,optimizer=\"nesterov\",weight_init=\"random\"):\n",
        "\n",
        "        self.x_train,self.x_cv,self.y_train,self.y_cv = train_test_split(x_train, y_train, test_size=0.10, random_state=100,stratify=y_train)\n",
        "\n",
        "        np.random.seed(10)\n",
        "        self.gradient={}\n",
        "        for i in range(hidden_layers+2):\n",
        "            self.gradient[\"W\"+str(i)]=i;\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.hidden_layers_size = hidden_layers_size\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.batch = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.activation_func = activation_func\n",
        "        self.learning_rate = learning_rate\n",
        "        self.decay_rate = decay_rate\n",
        "        self.optimizer = optimizer\n",
        "        for i in range(hidden_layers+2):\n",
        "            self.gradient[\"b\"+str(i)]=i;\n",
        "        self.weight_init = weight_init\n",
        "        self.beta = beta\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.layers = [self.input_dim] + self.hidden_layers*[self.hidden_layers_size] + [self.output_dim]\n",
        "        layers = self.layers.copy()\n",
        "        self.activations = []\n",
        "        self.activation_gradients = []\n",
        "        #self.optimizer_list={'gradient_descent':self.gradient_descent,'sgd':self.sgd,'nesterov':self.nesterov,'nadam':self.nadam,'adam':self.adam,'momentum':self.momentum,'rmsprop':self.rmsprop}\n",
        "        self.weights_gradients = []\n",
        "        self.biases_gradients = []\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        n=len(layers)\n",
        "        for i in range(n-1):\n",
        "            if self.weight_init == 'random':\n",
        "                a=np.random.normal(0,0.5,(layers[i],layers[i+1]))\n",
        "                self.weights.append(a)\n",
        "                self.biases.append(np.random.normal(0,0.5,(layers[i+1])))\n",
        "            else :\n",
        "                std = np.sqrt(2/(layers[i]*layers[i+1]))\n",
        "                a=np.random.normal(0,std,(layers[i],layers[i+1]))\n",
        "                self.weights.append(a)\n",
        "                self.biases.append(np.random.normal(0,std,(layers[i+1])))\n",
        "            v1=np.zeros(layers[i])\n",
        "            self.activations.append(v1)\n",
        "            v2=np.zeros(layers[i+1])\n",
        "            self.activation_gradients.append(v2)\n",
        "            self.weights_gradients.append(np.zeros((layers[i],layers[i+1])))\n",
        "            self.biases_gradients.append(v2)\n",
        "        self.activations.append(np.zeros(layers[-1]))\n",
        "        #self.optimizer_list[optimizer](self.x_train,self.y_train)\n",
        "            \n",
        "\n",
        "    def sigmoid(self,activations):\n",
        "        res = []\n",
        "        for z in activations:\n",
        "            if z<-40:\n",
        "                res.append(0.0)\n",
        "            elif z>40:\n",
        "                res.append(1.0)\n",
        "            else:\n",
        "                res.append(1/(1+np.exp(-z)))\n",
        "        res=np.asarray(res)\n",
        "        return res\n",
        "\n",
        "    def tanh(self,activations):\n",
        "        res = []\n",
        "        for z in activations:\n",
        "            if z<-20:\n",
        "                res.append(-1.0)\n",
        "            elif z>20:\n",
        "                res.append(1.0)\n",
        "            else:\n",
        "                temp=(np.exp(z) - np.exp(-z))/(np.exp(z) + np.exp(-z))\n",
        "                res.append(temp)\n",
        "        res=np.asarray(res)\n",
        "        return res\n",
        "\n",
        "    def relu(self,activations):\n",
        "        res = []\n",
        "        for i in activations:\n",
        "            if i>0:\n",
        "                res.append(i)\n",
        "            else:\n",
        "                res.append(0)\n",
        "        res=np.asarray(res)\n",
        "        return res\n",
        "\n",
        "    def softmax(self,activations):\n",
        "        tot = 0\n",
        "        res=[]\n",
        "        for z in activations:\n",
        "            tot += np.exp(z)\n",
        "        res=np.asarray([np.exp(z)/tot for z in activations])\n",
        "        return res\n",
        "\n",
        "    def forward_propagation(self,x,y,weights,biases):\n",
        "        n = len(self.layers)\n",
        "        pre_activation=[]\n",
        "        for i in range(n-2):\n",
        "            pre_activation.append(i)\n",
        "        self.activations[0] = x\n",
        "        for i in range(n-2):\n",
        "            if self.activation_func == \"sigmoid\":\n",
        "                s=self.sigmoid(np.matmul(weights[i].T,self.activations[i])+biases[i])\n",
        "                self.activations[i+1] =s\n",
        "            elif self.activation_func == \"tanh\":\n",
        "                t=self.tanh(np.matmul(weights[i].T,self.activations[i])+biases[i])\n",
        "                self.activations[i+1] =t\n",
        "            elif self.activation_func == \"relu\":\n",
        "                r=self.relu(np.matmul(weights[i].T,self.activations[i])+biases[i])\n",
        "                self.activations[i+1] = r\n",
        "        temp=self.softmax(np.matmul(weights[n-2].T,self.activations[n-2])+biases[n-2])\n",
        "        self.activations[n-1] = temp      \n",
        "        return -(np.log2(self.activations[-1][y]))\n",
        "\n",
        "\n",
        "    def grad_w(self,i):\n",
        "        gw=np.matmul(self.activations[i].reshape((-1,1)),self.activation_gradients[i].reshape((1,-1)))\n",
        "        return gw\n",
        "\n",
        "\n",
        "    def grad_b(self,i):\n",
        "        gb=self.activation_gradients[i]\n",
        "        return gb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn = Neural_network(x_train,y_train,784,64,2,10)"
      ],
      "metadata": {
        "id": "DTI9g1GUShRE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.forward_propagation(x_train[0].reshape(784,),y_train[0],nn.weights,nn.biases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHg3Sf6WTfzj",
        "outputId": "82949227-ad35-42be-beb4-960c451ec114"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.107910471974991"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.activations[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfKOh9ZTUktd",
        "outputId": "44663c86-9281-41b8-e5bd-d893a415beac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.65284993e-02, 8.88077068e-02, 1.08257016e-03, 1.29130983e-02,\n",
              "       6.06017162e-01, 5.44504811e-03, 3.38257565e-02, 1.77357286e-01,\n",
              "       2.71822417e-05, 5.79956912e-02])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "asuOK6SAUn5G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}